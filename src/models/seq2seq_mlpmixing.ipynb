{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","mount_file_id":"12Avpbh1enW0uEawKznTlza-j6J_tffvl","authorship_tag":"ABX9TyOlroWu1ztjEIke9h+ZdadZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from torch.utils.data import Dataset\n","import numpy as np\n","import random\n","from sklearn.preprocessing import MinMaxScaler\n","import os\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n","import matplotlib.pyplot as plt\n","import torch.nn.utils.rnn as rnn_utils"],"metadata":{"id":"_8ivQ4NvvmDf","executionInfo":{"status":"aborted","timestamp":1703279950805,"user_tz":300,"elapsed":7,"user":{"displayName":"Loc Tran","userId":"16453192812197056024"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def collate_fn(batch):\n","    features, gaze_direction = zip(*batch)\n","\n","    # Pad sequences to the length of the longest sequence in the batch\n","    padded_features = rnn_utils.pad_sequence(features, batch_first=True, padding_value=0)\n","    padded_gaze_direction = rnn_utils.pad_sequence(gaze_direction, batch_first=True, padding_value=0)\n","\n","    return padded_features, padded_gaze_direction\n","\n","def normalize_data(data):\n","    scaler = MinMaxScaler(feature_range=(0, 1))\n","    return scaler.fit_transform(data), scaler"],"metadata":{"id":"yGvTiDV6vmSf","executionInfo":{"status":"aborted","timestamp":1703279950805,"user_tz":300,"elapsed":7,"user":{"displayName":"Loc Tran","userId":"16453192812197056024"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class GazeDirectionDataset(Dataset):\n","    def __init__(self, folder_path, sequence_length=5):\n","        self.sequence_length = sequence_length\n","        self.data = []\n","        self.feature = []\n","\n","        # Load and aggregate data from all CSV files in the folder\n","        for filename in os.listdir(folder_path):\n","            if filename.endswith('.csv'):\n","                file_path = os.path.join(folder_path, filename)\n","                data = pd.read_csv(file_path)\n","                features = data[['HeadX', 'HeadY', 'HeadZ','REyeRX', 'REyeRY', 'REyeRZ']].values\n","                gaze_data = data[['REyeRX', 'REyeRY', 'REyeRZ']].values\n","                self.data.append(gaze_data)\n","                self.feature.append(features)\n","\n","        # Concatenate and normalize the data\n","        all_data = np.concatenate(self.data, axis=0)\n","        all_data1 = np.concatenate(self.feature, axis=0)\n","\n","        self.normalized_features, self.scaler_features = normalize_data(all_data1)\n","\n","        self.normalized_gaze_data, self.scaler = normalize_data(all_data)\n","\n","    def __len__(self):\n","        return len(self.normalized_gaze_data) - self.sequence_length - 1\n","\n","    def __getitem__(self, idx):\n","        input_seq = self.normalized_features[idx:idx + self.sequence_length]\n","        target_seq = self.normalized_gaze_data[idx + 1:idx + self.sequence_length + 1]\n","\n","        input_seq = torch.tensor(input_seq, dtype=torch.float32)\n","        target_seq = torch.tensor(target_seq, dtype=torch.float32)\n","\n","        return input_seq, target_seq"],"metadata":{"id":"PJONBak9vjFX","executionInfo":{"status":"aborted","timestamp":1703279950805,"user_tz":300,"elapsed":7,"user":{"displayName":"Loc Tran","userId":"16453192812197056024"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# class GazeDirectionDataset(Dataset):\n","#     def __init__(self, data_dir):\n","#         self.data_dir = data_dir\n","#         self.file_list = [file for file in os.listdir(data_dir) if file.endswith('.csv')]\n","\n","#     def __len__(self):\n","#         return len(self.file_list)\n","\n","#     def __getitem__(self, idx):\n","#         file_name = self.file_list[idx]\n","#         file_path = os.path.join(self.data_dir, file_name)\n","\n","#         # Load the data from the text file with the correct delimiter\n","#         data = pd.read_csv(file_path, delimiter=',')  # Assuming comma-separated values\n","\n","#         # Extract features and labels (assuming 'GazeDirection' is the column to predict)\n","#         features = data[['HeadRX', 'HeadRY', 'HeadRZ']].values[::100]   # Exclude 'Timer' and gaze direction columns\n","#         # features = data[['HeadX', 'HeadY', 'HeadZ','HeadRX', 'HeadRY', 'HeadRZ']].values  # Exclude 'Timer' and gaze direction columns\n","\n","#         gaze_direction = data[['REyeRX', 'REyeRY', 'REyeRZ']].values[::100]\n","\n","#         # Convert to PyTorch tensors\n","#         features = torch.tensor(features, dtype=torch.float32)\n","#         gaze_direction = torch.tensor(gaze_direction, dtype=torch.float32)\n","\n","#         return features, gaze_direction"],"metadata":{"id":"XQon9D2Pyo6Q","executionInfo":{"status":"aborted","timestamp":1703279950805,"user_tz":300,"elapsed":6,"user":{"displayName":"Loc Tran","userId":"16453192812197056024"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# class Encoder(nn.Module):\n","#     def __init__(self, input_dim, latent_dim):\n","#         super(Encoder, self).__init__()\n","#         self.latent_dim = latent_dim\n","#         self.lstm1 = nn.LSTM(input_dim, self.latent_dim, batch_first=True)\n","#         self.lstm2 = nn.LSTM(self.latent_dim, self.latent_dim, batch_first=True)\n","\n","#     def forward(self, src):\n","#         print(\"encoder\",src.shape)\n","#         outputs, (hidden, cell) = self.lstm1(src)\n","#         outputs, (hidden, cell) = self.lstm2(outputs)\n","#         return hidden, cell\n","\n","# class Decoder(nn.Module):\n","#     def __init__(self, output_dim, latent_dim):\n","#         super(Decoder, self).__init__()\n","#         self.latent_dim = latent_dim\n","#         self.lstm1 = nn.LSTM(output_dim, self.latent_dim, batch_first=True)\n","#         self.lstm2 = nn.LSTM(self.latent_dim, self.latent_dim, batch_first=True)\n","#         self.fc_out = nn.Linear(self.latent_dim, output_dim)\n","\n","#     def forward(self, trg, hidden, cell):\n","#         print(\"decoder\",trg.shape)\n","\n","#         # trg = trg.unsqueeze(1)\n","#         output, (hidden, cell) = self.lstm1(trg, (hidden, cell))\n","#         output, (hidden, cell) = self.lstm2(output, (hidden, cell))\n","#         prediction = self.fc_out(output)\n","#         return prediction, hidden, cell\n","\n","# class Seq2Seq(nn.Module):\n","#     def __init__(self, encoder, decoder, device):\n","#         super(Seq2Seq, self).__init__()\n","#         self.encoder = encoder\n","#         self.decoder = decoder\n","#         self.device = device\n","\n","#     def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n","#         print(\"main\", src.shape, trg.shape)\n","\n","#         batch_size = trg.shape[0]\n","#         trg_len = trg.shape[1]\n","#         trg_vocab_size = self.decoder.fc_out.out_features\n","\n","#         outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n","#         hidden, cell = self.encoder(src)\n","#         # hidden = hidden.unsqueeze(1)\n","#         # cell = cell.unsqueeze(1)\n","\n","#         # input = trg[:, 0, :]\n","#         input = trg[:, 0, :].unsqueeze(1).float()\n","#         for t in range(1, trg_len):\n","#             output, hidden, cell = self.decoder(input, hidden, cell)\n","#             outputs[:,t,:] = output\n","#             top1 = output.argmax(1)\n","#             input = trg[:, t,:] if random.random() < teacher_forcing_ratio else top1\n","#         # for t in range(1, trg_len):\n","#         #   output, hidden, cell = self.decoder(input, hidden, cell)\n","#         #   print(f\"Decoder output shape at timestep {t}: {output.shape}\")\n","\n","#         #   outputs[:, t, :] = output.squeeze(1)\n","#         #   if output.shape[2] > 1:  # If more than one feature\n","#         #       top1 = output.argmax(2)  # Reduces to [batch_size, 1]\n","#         #       input = trg[:, t, :].unsqueeze(1) if random.random() < teacher_forcing_ratio else top1.unsqueeze(1)  # Reshape to [batch_size, 1, features]\n","#         #   else:\n","#         #       # If only one feature, use output directly as next input\n","#         #       input = trg[:, t, :].unsqueeze(1) if random.random() < teacher_forcing_ratio else output\n","\n","#         return outputs\n"],"metadata":{"id":"mcA88UAHvt77","executionInfo":{"status":"aborted","timestamp":1703279950805,"user_tz":300,"elapsed":6,"user":{"displayName":"Loc Tran","userId":"16453192812197056024"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Seq2Seq(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, num_layers=2, dropout=0.0, batch_first=True):\n","        super(Seq2Seq, self).__init__()\n","        self.num_layers = num_layers\n","        self.hidden_size = hidden_size\n","\n","        # Encoder\n","        self.encoder_lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, dropout=dropout, batch_first=batch_first)\n","\n","        # Decoder\n","        self.decoder_lstm = nn.LSTM(output_size, hidden_size, num_layers=num_layers, dropout=dropout, batch_first=batch_first)\n","\n","        # Dense layer for prediction\n","        self.decoder_dense = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, encoder_input, decoder_input):\n","        # Encoder\n","        _, (hidden, cell) = self.encoder_lstm(encoder_input)\n","\n","        # Decoder\n","        decoder_output, _ = self.decoder_lstm(decoder_input, (hidden, cell))\n","\n","        # Final prediction\n","        output = self.decoder_dense(decoder_output)\n","\n","        return output\n","\n","    def init_hidden(self, batch_size):\n","        # This is used to initialize the hidden and cell states if needed\n","        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n","        cell = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n","        return hidden, cell"],"metadata":{"id":"ShGC6zkzKvtj","executionInfo":{"status":"aborted","timestamp":1703279950805,"user_tz":300,"elapsed":6,"user":{"displayName":"Loc Tran","userId":"16453192812197056024"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Seq2Seq_nlpmixing(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(Seq2Seq_nlpmixing, self).__init__()\n","        self.encoder1 = nn.LSTM(input_size, hidden_size, batch_first=True)\n","        self.encoder2 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n","        self.decoder_lstm1 = nn.LSTM(output_size, hidden_size, batch_first=True)\n","        self.decoder_lstm2 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n","        self.decoder_dense = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, encoder_input, decoder_input, encoder_lengths=None):\n","        encoder1_outputs, _ = self.encoder1(encoder_input)\n","        encoder2_outputs, _ = self.encoder2(encoder1_outputs)\n","\n","        decoder1_outputs, _ = self.decoder_lstm1(decoder_input)\n","        decoder2_outputs, _ = self.decoder_lstm2(decoder1_outputs)\n","\n","        output = self.decoder_dense(decoder2_outputs)\n","\n","        return output"],"metadata":{"id":"QKMj3HkAVlfp","executionInfo":{"status":"aborted","timestamp":1703279950805,"user_tz":300,"elapsed":6,"user":{"displayName":"Loc Tran","userId":"16453192812197056024"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the dataset into training and validation sets\n","data_directory = os.path.expanduser(\"/content/drive/MyDrive/colab/ECE6123_Final_Project/processed_by_activity/presenting\")\n","# custom_dataset = GazeDirectionDataset(data_directory)\n","custom_dataset = GazeDirectionDataset(data_directory)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_dataset, val_dataset = train_test_split(custom_dataset, test_size=0.3, random_state=42, shuffle=False)\n","val_dataset, test_dataset = train_test_split(val_dataset, test_size=0.5, random_state=42)\n","input_size = 6  # Update based on your input features\n","hidden_size = 128\n","output_size = 3 # Update based on your output features\n","model = Seq2Seq(input_size, hidden_size, output_size).to(device)\n","learning_rate = 0.001\n","batch_size = 32\n","# Instantiate the model\n","# encoder = Encoder(INPUT_DIM, LATENT_DIM)\n","# decoder = Decoder(OUTPUT_DIM, LATENT_DIM)\n","# model = Seq2Seq(encoder, decoder, device).to(device)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n","\n","\n","# Loss function and optimizer\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","# check back if scheduler is needed\n","# scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n","scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=3, min_lr=1e-6, verbose=True)\n","\n","# Early stopping parameters\n","early_stopping_patience = 5\n","early_stopping_counter = 0\n","best_val_loss = float('inf')\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","\n","# cuda\n","# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","# Training loop\n","num_epochs = 30\n","train_losses = []\n","val_losses = []\n","for src, trg in train_dataloader:\n","  print(src.shape, trg.shape)\n","  break\n","print(custom_dataset,custom_dataset,custom_dataset)\n","# print(train_dataloader[0])"],"metadata":{"id":"IVkRATAkwFz5","executionInfo":{"status":"aborted","timestamp":1703279950805,"user_tz":300,"elapsed":6,"user":{"displayName":"Loc Tran","userId":"16453192812197056024"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the dataset into training and validation sets\n","data_directory = os.path.expanduser(\"/content/drive/MyDrive/colab/ECE6123_Final_Project/processed_by_activity/sweep\")\n","# custom_dataset = GazeDirectionDataset(data_directory)\n","custom_dataset = GazeDirectionDataset(data_directory)\n","\n","train_dataset, val_dataset = train_test_split(custom_dataset, test_size=0.3, random_state=42, shuffle=True)\n","val_dataset, test_dataset = train_test_split(val_dataset, test_size=0.5, random_state=42)\n","# Data loaders\n","# Instantiate the model\n","input_size = 6 # Update based on your input features\n","hidden_size = 64\n","output_size = 3 # Update based on your output features\n","seq2seq_model = Seq2Seq_nlpmixing(input_size, hidden_size, output_size)\n","learning_rate = 0.0001\n","batch_size = 32\n","\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n","\n","\n","# Loss function and optimizer\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(seq2seq_model.parameters(), lr=learning_rate)\n","# check back if scheduler is needed\n","# scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n","scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=3, min_lr=1e-6, verbose=True)\n","\n","# Early stopping parameters\n","early_stopping_patience = 5\n","early_stopping_counter = 0\n","best_val_loss = float('inf')\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","\n","# cuda\n","# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","seq2seq_model.to(device)\n","\n","# Training loop\n","num_epochs = 30\n","train_losses = []\n","val_losses = []\n","\n","\n","for epoch in range(num_epochs):\n","    total_train_loss = 0.0\n","    model.train()\n","\n","    for i, batch in enumerate(train_dataloader):\n","        features, gaze_direction = batch\n","        features, gaze_direction = features.to(device).float(), gaze_direction.to(device).float()\n","        # Assuming decoder_input is the same as target for simplicity (modify as needed)\n","        optimizer.zero_grad()\n","        output = model(features, gaze_direction)\n","        # output = seq2seq_model(gaze_direction)\n","\n","        loss = criterion(output, gaze_direction)\n","        loss.backward()\n","        optimizer.step()\n","        total_train_loss += loss.item()\n","        # print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(train_dataloader)}], Training Loss: {loss.item()}')\n","    # Validation\n","    model.eval()\n","\n","    with torch.no_grad():\n","        total_val_loss = 0.0\n","        for batch in val_dataloader:\n","            features, gaze_direction = batch\n","            features, gaze_direction = features.to(device), gaze_direction.to(device)\n","            decoder_input = gaze_direction\n","            # decoder_input = torch.zeros_like(gaze_direction)  # Initialize decoder input, replace with your logic if needed\n","            val_output = model(features, decoder_input)\n","            total_val_loss += criterion(val_output, gaze_direction).item()\n","\n","    average_train_loss = total_train_loss / len(train_dataloader)\n","    average_val_loss = total_val_loss / len(val_dataloader)\n","    train_losses.append(average_train_loss)\n","    val_losses.append(average_val_loss)\n","\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Average Training Loss: {average_train_loss}, Average Validation Loss: {average_val_loss}')\n","    # scheduler.step()\n","    scheduler.step(average_val_loss)\n","\n","    # Early stopping check\n","    if average_val_loss < best_val_loss:\n","        best_val_loss = average_val_loss\n","        early_stopping_counter = 0\n","    else:\n","        early_stopping_counter += 1\n","        if early_stopping_counter >= early_stopping_patience:\n","            print(\"Early stopping triggered.\")\n","            break\n","\n","# Save the model if needed\n","torch.save(seq2seq_model.state_dict(), 'seq2seq_mlp.pth')"],"metadata":{"id":"IJArRNMMwtfq","executionInfo":{"status":"aborted","timestamp":1703279950805,"user_tz":300,"elapsed":5,"user":{"displayName":"Loc Tran","userId":"16453192812197056024"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","plt.plot(train_losses, label='Training Loss')\n","plt.plot(val_losses, label='Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('seq2seq + MLP mixing: Cleaning')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"uLgExq36X2SV","executionInfo":{"status":"aborted","timestamp":1703279950805,"user_tz":300,"elapsed":5,"user":{"displayName":"Loc Tran","userId":"16453192812197056024"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import torch\n","from torch.utils.data import Dataset\n","\n","## nlp mixing\n","\n","class GazeDirectionDataset(Dataset):\n","    def __init__(self, folder_path, sequence_length=5, num_users=None):\n","        self.sequence_length = sequence_length\n","        self.num_users = num_users  # number of users to include in the other_users_data\n","        self.data = []\n","        self.features = []\n","        self.other_users_data = []\n","\n","        # Load and aggregate data from all CSV files in the folder\n","        csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n","        for filename in csv_files:\n","            file_path = os.path.join(folder_path, filename)\n","            data = pd.read_csv(file_path)\n","            features = data[['HeadX', 'HeadY', 'HeadZ', 'REyeRX', 'REyeRY', 'REyeRZ']].values\n","            gaze_data = data[['REyeRX', 'REyeRY', 'REyeRZ']].values\n","            self.data.append(gaze_data)\n","            self.features.append(features)\n","\n","        # Here we assume that the first user is the target user\n","        # and the rest are other users to be used for mixing\n","        self.normalized_features, self.scaler_features = normalize_data(np.concatenate(self.features, axis=0))\n","        self.normalized_gaze_data, self.scaler = normalize_data(np.concatenate(self.data, axis=0))\n","\n","        num_samples = self.normalized_gaze_data.shape[0] // len(csv_files)\n","        num_features = self.normalized_gaze_data.shape[1]\n","\n","        self.normalized_gaze_data = self.normalized_gaze_data.reshape(len(csv_files), num_samples, num_features)\n","\n","        # If num_users is provided, select a subset of users for other_users_data\n","        if num_users is not None and num_users <= len(csv_files):\n","\n","            # Select a subset of users for other_users_data if num_users is provided\n","            self.other_users_data = self.normalized_gaze_data[:, :num_users-1, :]\n","        else:\n","            # Use data from all other users\n","            self.other_users_data = self.normalized_gaze_data[:, 1:, :]\n","\n","    def __len__(self):\n","        return len(self.normalized_gaze_data) - self.sequence_length - 1\n","\n","    def __getitem__(self, idx):\n","        input_seq = self.normalized_features[idx:idx + self.sequence_length]\n","        target_seq = self.normalized_gaze_data[idx + 1:idx + self.sequence_length + 1]\n","        # Here we need to provide the other users' data as well\n","        other_users_seq = self.other_users_data[idx + 1:idx + self.sequence_length + 1]\n","\n","        input_seq = torch.tensor(input_seq, dtype=torch.float32)\n","        target_seq = torch.tensor(target_seq, dtype=torch.float32)\n","        other_users_seq = torch.tensor(other_users_seq, dtype=torch.float32)\n","\n","        return input_seq, target_seq, other_users_seq\n"],"metadata":{"id":"rPfoconNMrsn","executionInfo":{"status":"aborted","timestamp":1703279950806,"user_tz":300,"elapsed":5,"user":{"displayName":"Loc Tran","userId":"16453192812197056024"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class Seq2SeqWithMLPMixing(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, num_users, num_layers=2, dropout=0.0, batch_first=True):\n","        super(Seq2SeqWithMLPMixing, self).__init__()\n","        self.num_layers = num_layers\n","        self.hidden_size = hidden_size\n","\n","        # Encoder\n","        self.encoder_lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, dropout=dropout, batch_first=batch_first)\n","\n","        # Decoder\n","        self.decoder_lstm = nn.LSTM(output_size, hidden_size, num_layers=num_layers, dropout=dropout, batch_first=batch_first)\n","\n","        # Dense layer for prediction\n","        self.decoder_dense = nn.Linear(hidden_size, output_size)\n","\n","        # MLP for mixing other users' data\n","        self.mlp_mixing = nn.Sequential(\n","            nn.Linear(hidden_size + (num_users - 1) * output_size, hidden_size),\n","            nn.ReLU(),\n","            nn.Linear(hidden_size, output_size)\n","        )\n","\n","    def forward(self, encoder_input, decoder_input, other_users_data=None):\n","        # Encoder\n","        _, (hidden, cell) = self.encoder_lstm(encoder_input)\n","\n","        # Decoder\n","        decoder_output, _ = self.decoder_lstm(decoder_input, (hidden, cell))\n","\n","        # If other users' data is provided, mix it using MLP\n","        if other_users_data is not None:\n","            # Flatten the other users' data to match the batch and feature dimensions\n","            other_users_data_flat = other_users_data.view(other_users_data.size(0), -1)\n","            # Concatenate the decoder output with the other users' data\n","            mixed_input = torch.cat((decoder_output, other_users_data_flat), dim=2)\n","            # Pass through the MLP mixing layer\n","            decoder_output = self.mlp_mixing(mixed_input)\n","\n","        # Final prediction\n","        output = self.decoder_dense(decoder_output)\n","\n","        return output\n","\n"],"metadata":{"id":"huG4Jl70Mptz","executionInfo":{"status":"aborted","timestamp":1703279950806,"user_tz":300,"elapsed":5,"user":{"displayName":"Loc Tran","userId":"16453192812197056024"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class GazeDirectionDataset(Dataset):\n","    def __init__(self, folder_path, sequence_length=5):\n","        self.sequence_length = sequence_length\n","        data_list = []\n","        feature_list = []\n","\n","        # Load and aggregate data from all CSV files in the folder\n","        for filename in os.listdir(folder_path):\n","            if filename.endswith('.csv'):\n","                file_path = os.path.join(folder_path, filename)\n","                data = pd.read_csv(file_path)\n","                features = data[['HeadX', 'HeadY', 'HeadZ', 'REyeRX', 'REyeRY', 'REyeRZ']].values\n","                gaze_data = data[['REyeRX', 'REyeRY', 'REyeRZ']].values\n","                data_list.append(gaze_data)\n","                feature_list.append(features)\n","\n","        # Normalize the data using the external function\n","        self.normalized_features, self.scaler_features = normalize_data(np.concatenate(feature_list, axis=0))\n","        self.normalized_gaze_data, self.scaler = normalize_data(np.concatenate(data_list, axis=0))\n","\n","    def __len__(self):\n","        return len(self.normalized_gaze_data) - self.sequence_length - 1\n","\n","    def __getitem__(self, idx):\n","        # Finding the right sequence in the list of sequences\n","        for data_seq, feature_seq in zip(self.normalized_gaze_data, self.normalized_features):\n","            if idx < len(data_seq) - self.sequence_length:\n","                input_seq = feature_seq[idx:idx + self.sequence_length]\n","                target_seq = data_seq[idx + 1:idx + self.sequence_length + 1]\n","                break\n","            idx -= len(data_seq) - self.sequence_length\n","\n","        input_seq = torch.tensor(input_seq, dtype=torch.float32)\n","        target_seq = torch.tensor(target_seq, dtype=torch.float32)\n","\n","        return input_seq, target_seq"],"metadata":{"id":"tNgyYHIeO8TF","executionInfo":{"status":"aborted","timestamp":1703279950806,"user_tz":300,"elapsed":5,"user":{"displayName":"Loc Tran","userId":"16453192812197056024"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the dataset into training and validation sets\n","data_directory = os.path.expanduser(\"/content/drive/MyDrive/colab/ECE6123_Final_Project/processed_by_activity/sweep\")\n","# custom_dataset = GazeDirectionDataset(data_directory)\n","custom_dataset = GazeDirectionDataset(data_directory,5)\n","\n","train_dataset, val_dataset = train_test_split(custom_dataset, test_size=0.3, random_state=42, shuffle=True)\n","val_dataset, test_dataset = train_test_split(val_dataset, test_size=0.5, random_state=42)\n","# Data loaders\n","# Instantiate the model\n","input_size = 6 # Update based on your input features\n","hidden_size = 64\n","output_size = 3 # Update based on your output features\n","seq2seq_model = Seq2Seq_nlpmixing(input_size, hidden_size, output_size)\n","learning_rate = 0.0001\n","batch_size = 32\n","\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n","\n","\n","# Loss function and optimizer\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(seq2seq_model.parameters(), lr=learning_rate)\n","# check back if scheduler is needed\n","# scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n","scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=3, min_lr=1e-6, verbose=True)\n","\n","# Early stopping parameters\n","early_stopping_patience = 5\n","early_stopping_counter = 0\n","best_val_loss = float('inf')\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","\n","# cuda\n","# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","seq2seq_model.to(device)\n","\n","# Training loop\n","num_epochs = 30\n","train_losses = []\n","val_losses = []\n","\n","\n","for epoch in range(num_epochs):\n","    total_train_loss = 0.0\n","    model.train()\n","\n","    for i, batch in enumerate(train_dataloader):\n","        features, gaze_direction = batch\n","        features, gaze_direction = features.to(device).float(), gaze_direction.to(device).float()\n","        # Assuming decoder_input is the same as target for simplicity (modify as needed)\n","        optimizer.zero_grad()\n","        output = model(features, gaze_direction)\n","        # output = seq2seq_model(gaze_direction)\n","\n","        loss = criterion(output, gaze_direction)\n","        loss.backward()\n","        optimizer.step()\n","        total_train_loss += loss.item()\n","        # print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(train_dataloader)}], Training Loss: {loss.item()}')\n","    # Validation\n","    model.eval()\n","\n","    with torch.no_grad():\n","        total_val_loss = 0.0\n","        for batch in val_dataloader:\n","            features, gaze_direction = batch\n","            features, gaze_direction = features.to(device), gaze_direction.to(device)\n","            decoder_input = gaze_direction\n","            # decoder_input = torch.zeros_like(gaze_direction)  # Initialize decoder input, replace with your logic if needed\n","            val_output = model(features, decoder_input)\n","            total_val_loss += criterion(val_output, gaze_direction).item()\n","\n","    average_train_loss = total_train_loss / len(train_dataloader)\n","    average_val_loss = total_val_loss / len(val_dataloader)\n","    train_losses.append(average_train_loss)\n","    val_losses.append(average_val_loss)\n","\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Average Training Loss: {average_train_loss}, Average Validation Loss: {average_val_loss}')\n","    # scheduler.step()\n","    scheduler.step(average_val_loss)\n","\n","    # Early stopping check\n","    if average_val_loss < best_val_loss:\n","        best_val_loss = average_val_loss\n","        early_stopping_counter = 0\n","    else:\n","        early_stopping_counter += 1\n","        if early_stopping_counter >= early_stopping_patience:\n","            print(\"Early stopping triggered.\")\n","            break\n","\n","# Save the model if needed\n","torch.save(seq2seq_model.state_dict(), 'seq2seq_mlp.pth')"],"metadata":{"id":"qPKdoed9MxcH","executionInfo":{"status":"aborted","timestamp":1703279950806,"user_tz":300,"elapsed":5,"user":{"displayName":"Loc Tran","userId":"16453192812197056024"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class GazeDirectionDataset(Dataset):\n","    def __init__(self, folder_path, sequence_length=5, num_users=None):\n","        self.sequence_length = sequence_length\n","        self.gaze_data = []\n","\n","        # Load and aggregate gaze data from all CSV files in the folder\n","        csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n","        for filename in csv_files:\n","            file_path = os.path.join(folder_path, filename)\n","            data = pd.read_csv(file_path)\n","            gaze_data = data[['REyeRX', 'REyeRY', 'REyeRZ']].values\n","            self.gaze_data.append(gaze_data)\n","\n","        # Normalize data\n","        all_gaze_data = np.concatenate(self.gaze_data, axis=0)\n","        self.normalized_gaze_data, self.scaler = normalize_data(all_gaze_data)\n","\n","        # Reshape to have 3 dimensions: (samples, timesteps, features)\n","        num_samples_per_user = self.normalized_gaze_data.shape[0] // len(csv_files)\n","        self.normalized_gaze_data = self.normalized_gaze_data.reshape(len(csv_files), num_samples_per_user, -1)\n","\n","        # Select a subset of users for other_users_data\n","        if num_users is not None and num_users <= len(csv_files):\n","            self.other_users_data = self.normalized_gaze_data[1:num_users, :, :]\n","        else:\n","            self.other_users_data = self.normalized_gaze_data[1:, :, :]\n","\n","    def __len__(self):\n","        return len(self.normalized_gaze_data[0]) - self.sequence_length - 1\n","\n","    def __getitem__(self, idx):\n","        if idx + self.sequence_length >= len(self.normalized_gaze_data[0]):\n","            raise IndexError(\"Index out of range for sequence generation\")\n","\n","        target_user_seq = self.normalized_gaze_data[0, idx:idx + self.sequence_length]\n","        target_user_seq = torch.tensor(target_user_seq, dtype=torch.float32)\n","\n","        other_users_seq = self.other_users_data[:, idx:idx + self.sequence_length]\n","        other_users_seq = torch.tensor(other_users_seq, dtype=torch.float32)\n","\n","        return target_user_seq, other_users_seq"],"metadata":{"id":"PibrFiGXXOTK","executionInfo":{"status":"aborted","timestamp":1703279950806,"user_tz":300,"elapsed":5,"user":{"displayName":"Loc Tran","userId":"16453192812197056024"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class Seq2SeqWithMLPMixing(nn.Module):\n","    def __init__(self, gaze_data_size, hidden_size, num_users, num_layers=2, dropout=0.0, batch_first=True):\n","        super(Seq2SeqWithMLPMixing, self).__init__()\n","        self.num_layers = num_layers\n","        self.hidden_size = hidden_size\n","\n","        # Encoder and Decoder use only gaze data\n","        self.encoder_lstm = nn.LSTM(gaze_data_size, hidden_size, num_layers=num_layers, dropout=dropout, batch_first=batch_first)\n","        self.decoder_lstm = nn.LSTM(gaze_data_size, hidden_size, num_layers=num_layers, dropout=dropout, batch_first=batch_first)\n","\n","        # Dense layer for prediction\n","        self.decoder_dense = nn.Linear(hidden_size, gaze_data_size)\n","\n","        # MLP for mixing other users' data\n","        self.mlp_mixing = nn.Sequential(\n","            nn.Linear(hidden_size + (num_users - 1) * gaze_data_size, hidden_size),\n","            nn.ReLU(),\n","            nn.Linear(hidden_size, gaze_data_size)\n","        )\n","\n","    def forward(self, encoder_input, decoder_input, other_users_data=None):\n","        # Encoder\n","        _, (hidden, cell) = self.encoder_lstm(encoder_input)\n","\n","        # Decoder\n","        decoder_output, _ = self.decoder_lstm(decoder_input, (hidden, cell))\n","\n","        # If other users' data is provided, mix it using MLP\n","        if other_users_data is not None:\n","            other_users_data_flat = other_users_data.view(other_users_data.size(0), -1)\n","            mixed_input = torch.cat((decoder_output, other_users_data_flat), dim=2)\n","            decoder_output = self.mlp_mixing(mixed_input)\n","\n","        # Final prediction\n","        output = self.decoder_dense(decoder_output)\n","\n","        return output\n","\n","# Example usage\n","gaze_data_size = 3  # Assuming gaze data has 3 features (REyeRX, REyeRY, REyeRZ)\n","num_users = 5  # Number of users including the target user\n","latent_dim = 256  # Hidden size for LSTM layers\n","\n","model = Seq2SeqWithMLPMixing(gaze_data_size, latent_dim, num_users)\n"],"metadata":{"id":"Z-jO9cIBXPd-","executionInfo":{"status":"aborted","timestamp":1703279950806,"user_tz":300,"elapsed":5,"user":{"displayName":"Loc Tran","userId":"16453192812197056024"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sequence_length = 5\n","num_users = 5  # Including the target user\n","batch_size = 32\n","num_epochs = 10\n","learning_rate = 0.001\n","gaze_data_size = 3  # Assuming 3 features for gaze data\n","latent_dim = 256  # Hidden size for LSTM layers\n","data_directory = os.path.expanduser(\"/content/drive/MyDrive/colab/ECE6123_Final_Project/processed_by_activity/sweep\")\n","\n","# Load the dataset\n","dataset = GazeDirectionDataset(data_directory, sequence_length, num_users)\n","\n","# Split dataset into training and validation sets\n","train_dataset, val_dataset = train_test_split(dataset, test_size=0.2)\n","\n","# Create DataLoaders for training and validation\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Initialize the model\n","model = Seq2SeqWithMLPMixing(gaze_data_size, latent_dim, num_users)\n","model.train()\n","\n","# Define loss function and optimizer\n","criterion = torch.nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Training Loop\n","for epoch in range(num_epochs):\n","    total_loss = 0\n","    for target_user_seq, other_users_seq in train_loader:\n","        # Forward pass\n","        optimizer.zero_grad()\n","        output = model(target_user_seq, target_user_seq[:, 1:, :], other_users_seq)\n","        loss = criterion(output, target_user_seq[:, 1:, :])\n","\n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    avg_loss = total_loss / len(train_loader)\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n","\n","    # Validation (optional, but recommended)\n","    model.eval()\n","    with torch.no_grad():\n","        val_loss = 0\n","        for target_user_seq, other_users_seq in val_loader:\n","            output = model(target_user_seq, target_user_seq[:, 1:, :], other_users_seq)\n","            loss = criterion(output, target_user_seq[:, 1:, :])\n","            val_loss += loss.item()\n","        avg_val_loss = val_loss / len(val_loader)\n","    print(f'Validation Loss: {avg_val_loss:.4f}')\n","    model.train()\n"],"metadata":{"id":"vu6FTt5FXtLh","executionInfo":{"status":"aborted","timestamp":1703279950806,"user_tz":300,"elapsed":5,"user":{"displayName":"Loc Tran","userId":"16453192812197056024"}}},"execution_count":null,"outputs":[]}]}